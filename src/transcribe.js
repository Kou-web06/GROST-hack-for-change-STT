// src/live_transcribe.js
// Node.js 18å¯¾ç­–
const { File } = require('node:buffer');
globalThis.File = File;

const path = require('path');
require('dotenv').config({ path: path.resolve(__dirname, '../.env') }); 

const fs = require('fs');
const OpenAI = require('openai');
const { spawn } = require('child_process');
const chokidar = require('chokidar');

// è¨­å®š
const SEGMENT_TIME = 6; // ä½•ç§’ã”ã¨ã«æ–‡å­—èµ·ã“ã—ã™ã‚‹ã‹ï¼ˆçŸ­ã™ãã‚‹ã¨æ–‡è„ˆãŒåˆ‡ã‚Œã‚‹ã€é•·ã„ã¨ãƒ©ã‚°ã«ãªã‚‹ï¼‰
const OUTPUT_DIR = path.resolve(__dirname, '../segments'); // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å ´æ‰€
// â˜…ã“ã“ã«HLSã®URLã‚’å…¥ã‚Œã‚‹ï¼
const HLS_URL = 'http://hlsvod.shugiintv.go.jp/vod/_definst_/amlst:2025/2025-1105-1300-00/playlist.m3u8'; 

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ãƒ€ãƒŸãƒ¼é–¢æ•°ï¼ˆè¡Œã”ã¨ã«é€ä¿¡ï¼‰
async function passToNextStep(text) {
  console.log(`ğŸš€ é€ä¿¡: "${text}"`);
  // ã“ã“ã«Socket.ioãªã©ã§ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«é€ã‚‹å‡¦ç†ã‚’æ›¸ã
}

async function main() {
  console.log("ğŸ”´ ãƒ©ã‚¤ãƒ–æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ï¼");

  // 1. ä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ã‚’åˆæœŸåŒ–ï¼ˆå‰å›ã®ã‚´ãƒŸã‚’å‰Šé™¤ï¼‰
  if (fs.existsSync(OUTPUT_DIR)) {
    fs.rmSync(OUTPUT_DIR, { recursive: true, force: true });
  }
  fs.mkdirSync(OUTPUT_DIR);

  // 2. FFmpegã‚’èµ·å‹•ã—ã¦ã€HLSã‚’mp3ã«åˆ»ã¿ç¶šã‘ã‚‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†
  console.log(`ğŸ¥ ã‚¹ãƒˆãƒªãƒ¼ãƒ å—ä¿¡é–‹å§‹: ${HLS_URL}`);
  const ffmpeg = spawn('ffmpeg', [
    '-i', HLS_URL,           // å…¥åŠ›å…ƒ
    '-f', 'segment',         // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ãƒ¢ãƒ¼ãƒ‰
    '-segment_time', SEGMENT_TIME, // åˆ†å‰²ã™ã‚‹ç§’æ•°
    '-reset_timestamps', '1',
    '-ac', '1',              // ãƒ¢ãƒãƒ©ãƒ«ï¼ˆè»½é‡åŒ–ï¼‰
    '-ab', '32k',            // ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆï¼ˆè»½é‡åŒ–ï¼‰
    path.join(OUTPUT_DIR, 'out%03d.mp3') // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (out001.mp3, out002.mp3...)
  ]);

  // FFmpegã®ãƒ­ã‚°ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã®ã¿è¡¨ç¤ºï¼‰
  ffmpeg.stderr.on('data', (data) => {
    // console.log(`ffmpeg: ${data}`); // ã†ã‚‹ã•ã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã€‚ãƒ‡ãƒãƒƒã‚°æ™‚ã¯å¤–ã—ã¦ã€‚
  });

  // 3. ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç›£è¦–ã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒã§ããŸã‚‰Whisperã¸ï¼
  const watcher = chokidar.watch(OUTPUT_DIR, {
    persistent: true,
    awaitWriteFinish: { stabilityThreshold: 2000, pollInterval: 100 } // æ›¸ãè¾¼ã¿å®Œäº†ã‚’ç¢ºå®Ÿã«å¾…ã¤
  });

  watcher.on('add', async (filePath) => {
    const fileName = path.basename(filePath);
    console.log(`\nğŸ“‚ æ–°ã—ã„éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œçŸ¥: ${fileName}`);

    try {
      // Whisperã«æŠ•ã’ã‚‹
      const audioFile = fs.createReadStream(filePath);
      const transcription = await openai.audio.transcriptions.create({
        file: audioFile,
        model: "whisper-1",
        language: "ja",
        response_format: "verbose_json", // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ä»˜ãã§å–å¾—
      });

      // çµæœã‚’å‡¦ç†
      if (transcription.segments) {
        for (const segment of transcription.segments) {
          const text = segment.text.trim();
          if (text.length > 0) await passToNextStep(text);
        }
      } else {
        if (transcription.text.trim().length > 0) await passToNextStep(transcription.text);
      }

      // å‡¦ç†ãŒçµ‚ã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯æ¶ˆã™ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯æº¢ã‚Œé˜²æ­¢ï¼‰
      fs.unlinkSync(filePath);
      console.log(`ğŸ—‘ï¸ å‡¦ç†å®Œäº†ãƒ»å‰Šé™¤: ${fileName}`);

    } catch (err) {
      console.error(`ğŸ˜­ ã‚¨ãƒ©ãƒ¼ (${fileName}):`, err.message);
    }
  });

  console.log(`ğŸ‘€ ${SEGMENT_TIME}ç§’ã”ã¨ã«éŸ³å£°ã‚’åˆ‡ã‚Šå‡ºã—ã¦ç›£è¦–ä¸­...`);
}

main();